{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn import metrics\n",
        "\n",
        "cancer = datasets.load_breast_cancer()\n",
        "\n",
        "X = cancer.data\n",
        "y = cancer.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Linear Regression': LogisticRegression(),\n",
        "    'SVM': svm.SVC(kernel='rbf', probability=True),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f'By using {name}')\n",
        "\n",
        "    if hasattr(model, 'predict_proba'):\n",
        "        print(\"Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
        "        print(\"Precision:\", metrics.precision_score(y_test, y_pred))\n",
        "        print(\"Recall:\", metrics.recall_score(y_test, y_pred))\n",
        "    else:\n",
        "        print(\"Not a classification model.\")\n",
        "\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kw0fBGP8OKR",
        "outputId": "478d94aa-5f91-415e-f107-a0d2321bef8e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "By using Logistic Regression\n",
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "\n",
            "By using Linear Regression\n",
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "\n",
            "By using SVM\n",
            "Accuracy: 0.9473684210526315\n",
            "Precision: 0.922077922077922\n",
            "Recall: 1.0\n",
            "\n",
            "By using Decision Tree\n",
            "Accuracy: 0.9473684210526315\n",
            "Precision: 0.9577464788732394\n",
            "Recall: 0.9577464788732394\n",
            "\n",
            "By using Random Forest\n",
            "Accuracy: 0.9649122807017544\n",
            "Precision: 0.958904109589041\n",
            "Recall: 0.9859154929577465\n",
            "\n",
            "By using KNN\n",
            "Accuracy: 0.956140350877193\n",
            "Precision: 0.9342105263157895\n",
            "Recall: 1.0\n",
            "\n",
            "By using Naive Bayes\n",
            "Accuracy: 0.9736842105263158\n",
            "Precision: 0.9594594594594594\n",
            "Recall: 1.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}